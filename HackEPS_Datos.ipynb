{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAJujS4dLYcs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "!pip install fuzzywuzzy python-Levenshtein\n",
        "from fuzzywuzzy import process\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descomprimir archivos .zip"
      ],
      "metadata": {
        "id": "rH-FC6LW4MyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directorio_zip = '/content/*.zip'\n",
        "files = glob.glob(directorio_zip)\n",
        "\n",
        "for archivo_zip in files:\n",
        "  with zipfile.ZipFile(archivo_zip, 'r') as zip_ref:\n",
        "      zip_ref.extractall('/content/')"
      ],
      "metadata": {
        "id": "oCS6Q-D_4Ql4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Barrios de Los Ángeles\n",
        "gdf_barrios = gpd.read_file('/content/Data2/Neighborhood_Councils.geojson')\n",
        "gdf_barrios = gdf_barrios[['NAME', 'geometry']]\n",
        "gdf_barrios.columns = ['Neighborhood', 'geometry']\n",
        "gdf_barrios"
      ],
      "metadata": {
        "id": "pbvnP5S1eXTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Crime Data csv\n",
        "df_crimenes = pd.read_csv('/content/Data2/Crime_Data_from_2020_to_Present_20251122.csv')\n",
        "\n",
        "# Conseguimos datos de longitud y latitud válidos del dataset de crímenes\n",
        "df_crimenes = df_crimenes[\n",
        "    (df_crimenes['LAT'] != 0) &\n",
        "    (df_crimenes['LON'] != 0) &\n",
        "    (df_crimenes['LAT'].notnull())\n",
        "].copy()\n",
        "print(f\"Procesando {len(df_crimenes)} crímenes con coordenadas válidas...\")\n",
        "\n",
        "# Convertimos de DataFrame a GeoFrame, el df de crímenes\n",
        "gdf_crimenes = gpd.GeoDataFrame(df_crimenes, geometry=gpd.points_from_xy(df_crimenes['LON'], df_crimenes['LAT'],\n",
        "                                                                         crs='EPSG:4326'))\n",
        "# Verificamos sistema de coordenadas (ambos tienen que estar en el mismo para poder trabajar sobre ellos)\n",
        "if gdf_barrios.crs != gdf_crimenes.crs:\n",
        "  gdf_barrios = gdf_barrios.to_crs(\"EPSG:4326\")\n",
        "\n",
        "# Spatial join (para poder identificar cada crímen con el barrio mediante las coordenadas).\n",
        "# La variable tiene todas las columnas de crímenes junto con el barrio\n",
        "crimenes_barrios = gpd.sjoin(gdf_crimenes, gdf_barrios, how='left', predicate='within')\n",
        "\n",
        "# Resultados para tener el conteo\n",
        "num_crimenes_barrio = crimenes_barrios['Neighborhood'].value_counts().reset_index()\n",
        "num_crimenes_barrio.columns = ['Neighborhood', 'Crimenes_Barrio']\n",
        "num_crimenes_barrio.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "E6VZcBQC-S7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precio de compra de vivienda en Los Ángeles\n",
        "df_home_value = pd.read_csv('/content/Data1/Precio_Compra_LA.csv')\n",
        "df_home_value = df_home_value [\n",
        "    (df_home_value['City'] == 'Los Angeles') &\n",
        "    (df_home_value['State'] == 'CA')\n",
        "].copy()\n",
        "\n",
        "# Identificar columnas con las que haremos el promedio de valores\n",
        "cols_24_25 = [col for col in df_home_value.columns if '2024' in col or '2025' in col]\n",
        "\n",
        "# Calculamos el promedio del precio de compra de esos años\n",
        "df_home_value['Promedio_precio'] = df_home_value[cols_24_25].mean(axis=1)\n",
        "\n",
        "# Nos quedamos con las columnas necesarias\n",
        "df_home_value = df_home_value[['RegionName', 'Promedio_precio']]\n",
        "df_home_value.columns = ['Neighborhood', 'Avg_price']\n",
        "df_home_value.reset_index()"
      ],
      "metadata": {
        "id": "5rJk-W7rPuxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Densidad de población Los Ángeles"
      ],
      "metadata": {
        "id": "pzJ6_qHTpsFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el mapa de California y lo limpiamos (shapefile)\n",
        "# Primero descomprimimos el archivo ZIP\n",
        "with zipfile.ZipFile(\"tl_2023_06_tract.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "gdf_mapa = gpd.read_file('tl_2023_06_tract.shp')\n",
        "\n",
        "# Nos quedamos solo con Los Ángeles\n",
        "gdf_mapa_LA = gdf_mapa[\n",
        "    (gdf_mapa['COUNTYFP'] == '037') &\n",
        "    (gdf_mapa['STATEFP'] == '06')\n",
        "].copy()\n",
        "#print(f\"Polígonos cargados: {len(gdf_mapa_LA)}\")\n",
        "\n",
        "# Cargamos los datos de la población de Los Ángeles\n",
        "df_population = pd.read_csv('/content/Data1/Population_LA.csv', header=1)\n",
        "\n",
        "# Renombramos las columnas\n",
        "df_population = df_population.rename(columns={\n",
        "    df_population.columns[0]: 'GEOID',\n",
        "    df_population.columns[2]: 'Total_Population'\n",
        "})\n",
        "\n",
        "# Limpiamos el ID para eliminar la parte \"1400000US\" del ID_Cens\n",
        "df_population['GEOID'] = df_population['GEOID'].str.replace('1400000US', '')\n",
        "\n",
        "# Merge para realizar la intersección de los datos y sacar la población por barrio, unimos mediante 'Geometry_ID_Cens'\n",
        "gdf_population = gdf_mapa_LA.merge(df_population, on='GEOID', how='inner')\n",
        "\n",
        "# Calculamos la densidad (personas / km2)\n",
        "gdf_population = gdf_population.to_crs(\"EPSG:26911\") # Representamos la proyección de las coordenadas según la franja de Los Ángeles (UTM Zona 11N)\n",
        "gdf_population['Area_km2'] = gdf_population.area / 10**6 # Para que sean km2\n",
        "gdf_population['Densidad_Poblacion'] = gdf_population['Total_Population'] / gdf_population['Area_km2']\n",
        "\n",
        "#print(gdf_population[['GEOID', 'Total_Population', 'Densidad_Poblacion']].head())\n",
        "\n",
        "# Relacionamos la densidad de población de cada ID Geometrico con el barrio de LA que corresponda\n",
        "gdf_population = gdf_population.to_crs(\"EPSG:26911\")\n",
        "gdf_barrios = gdf_barrios.to_crs(\"EPSG:26911\")\n",
        "\n",
        "# Calculamos el tamaño del territorio para poder relacionarlo con los barrios\n",
        "gdf_population['area_tract_original'] = gdf_population.geometry.area\n",
        "\n",
        "# Hacemos el cálculo de la intersección. Si un tramo cae entre dos barrios, se generan dos filas\n",
        "gdf_intersec = gpd.overlay(gdf_barrios, gdf_population, how='intersection')\n",
        "\n",
        "# Cálculo del área de la nueva intersección\n",
        "gdf_intersec['area_interseccion'] = gdf_intersec.geometry.area\n",
        "\n",
        "# Cálculo del ratio del tramo obtenido para saber qué porcentaje pertenece al tramo original\n",
        "gdf_intersec['ratio'] = gdf_intersec['area_interseccion'] / gdf_intersec['area_tract_original']\n",
        "\n",
        "# Asignación de población proporcional (según el número de personas y el ratio)\n",
        "gdf_intersec['asignacion_poblacion'] = gdf_intersec['Total_Population'] * gdf_intersec['ratio']\n",
        "\n",
        "# Resultados por barrio\n",
        "# Agrupamos tramos para tener el total por barrio\n",
        "df_demografia_barrio = gdf_intersec.groupby('Neighborhood')[['asignacion_poblacion', 'area_interseccion']].sum().reset_index()\n",
        "\n",
        "# Convertimos área a km2\n",
        "df_demografia_barrio['Area_km2'] = df_demografia_barrio['area_interseccion'] / 10**6\n",
        "\n",
        "# Calculamos densidad final\n",
        "df_demografia_barrio['Densidad_Poblacion'] = df_demografia_barrio['asignacion_poblacion'] / df_demografia_barrio['Area_km2']\n",
        "df_demografia_barrio.head()\n"
      ],
      "metadata": {
        "id": "nsBhZy0VoFQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estilo de vida y servicios y mobilidad y transporte en LA"
      ],
      "metadata": {
        "id": "XObWBEWC9-43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscamos en el área de 'Los Angeles'\n",
        "# nwr = node, way, relation (buscamos puntos, líneas y polígonos)\n",
        "\n",
        "overpass_query = \"\"\"\n",
        "[out:json][timeout:90];\n",
        "area[\"name\"=\"Los Angeles\"][\"admin_level\"=\"8\"]->.searchArea;\n",
        "(\n",
        "  // ESTILO DE VIDA (Comida, Ocio...)\n",
        "  nwr[\"amenity\"=\"restaurant\"](area.searchArea);\n",
        "  nwr[\"amenity\"=\"cafe\"](area.searchArea);\n",
        "  nwr[\"amenity\"=\"bar\"](area.searchArea);\n",
        "  nwr[\"leisure\"=\"park\"](area.searchArea);\n",
        "  nwr[\"leisure\"=\"fitness_centre\"](area.searchArea);\n",
        "\n",
        "  // SERVICIOS\n",
        "  nwr[\"amenity\"=\"hospital\"](area.searchArea);\n",
        "  nwr[\"amenity\"=\"school\"](area.searchArea);\n",
        "  nwr[\"shop\"=\"supermarket\"](area.searchArea);\n",
        "  nwr[\"public_transport\"=\"station\"](area.searchArea);\n",
        ");\n",
        "out center;\n",
        "\"\"\"\n",
        "\n",
        "# URL de la API pública\n",
        "url = \"http://overpass-api.de/api/interpreter\"\n",
        "response = requests.get(url, params={'data': overpass_query})\n",
        "\n",
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    elements = data['elements']\n",
        "\n",
        "    amenities_list = []\n",
        "\n",
        "    for element in elements:\n",
        "        # Extraemos los tags\n",
        "        tags = element.get('tags', {})\n",
        "\n",
        "        # Determinamos la categoría principal\n",
        "        category = \"Other\"\n",
        "        if 'amenity' in tags:\n",
        "            category = tags['amenity']\n",
        "        elif 'leisure' in tags:\n",
        "            category = tags['leisure']\n",
        "        elif 'shop' in tags:\n",
        "            category = tags['shop']\n",
        "        elif 'public_transport' in tags:\n",
        "            category = 'public_transport'\n",
        "\n",
        "        # Obtenemos latitud/longitud (si es un 'way' o 'relation', usamos el centro calculado por la API)\n",
        "        lat = element.get('lat') or element.get('center', {}).get('lat')\n",
        "        lon = element.get('lon') or element.get('center', {}).get('lon')\n",
        "\n",
        "        if lat and lon:\n",
        "            amenities_list.append({\n",
        "                'Name': tags.get('name', 'Unknown'),\n",
        "                'Category': category,\n",
        "                'Type': element['type'],\n",
        "                'LAT': lat,\n",
        "                'LON': lon\n",
        "            })\n",
        "\n",
        "    # Crear DataFrame\n",
        "    df_servicios = pd.DataFrame(amenities_list)\n",
        "    df_servicios = df_servicios[~df_servicios['Category'].isin(['community_centre', 'ferry_terminal'])]\n",
        "    print(\"\\nResumen por Categoría:\")\n",
        "    print(df_servicios['Category'].value_counts())\n",
        "\n",
        "else:\n",
        "    print(f\"Error en la consulta: {response.status_code}\")"
      ],
      "metadata": {
        "id": "R1G_s4dB-DdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agrupamos por barrios de LA"
      ],
      "metadata": {
        "id": "oGO__bjJEF90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformamos a GeoDataFrame\n",
        "gdf_servicios = gpd.GeoDataFrame(df_servicios,\n",
        "                                 geometry=gpd.points_from_xy(df_servicios['LON'], df_servicios['LAT']),\n",
        "                                 crs=\"EPSG:4326\") # Devolvemos coordenadas en grados\n",
        "\n",
        "# Comprobamos crs de ambos gdfs.\n",
        "if gdf_servicios.crs != gdf_barrios.crs:\n",
        "    gdf_servicios = gdf_servicios.to_crs(gdf_barrios.crs)\n",
        "\n",
        "# Spatial join --> Aqui tendremos una fila por cada servicio y barrio\n",
        "servicios_barrios = gpd.sjoin(gdf_servicios, gdf_barrios, how='inner', predicate='within')\n",
        "\n",
        "# Contamos por categoria para agrupar en cada barrio\n",
        "servicios = pd.crosstab(servicios_barrios['Neighborhood'], servicios_barrios['Category'])\n",
        "servicios = servicios.reset_index()\n",
        "servicios"
      ],
      "metadata": {
        "id": "ciJ3AhNqEDUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FuzzyWuzzy\n",
        "### Aplicamos esta técnica para tener los mismos nombres de neighborhood que en el df original cargados del geojson, ya que, no coindician."
      ],
      "metadata": {
        "id": "1BP92q3jfg4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenemos la lista original de tus barrios\n",
        "barrios_oficiales = gdf_barrios['Neighborhood'].unique()\n",
        "\n",
        "# Preparamos el diccionario de precios de Zillow para buscar rápido\n",
        "dict_precios = pd.Series(\n",
        "    df_home_value.Avg_price.values,\n",
        "    index=df_home_value.Neighborhood\n",
        ").to_dict()\n",
        "\n",
        "nombres_zillow = list(dict_precios.keys())\n",
        "\n",
        "# Algoritmo de emparejamiento (Fuzzy Matching)\n",
        "mapa_precios = {}\n",
        "\n",
        "for barrio in barrios_oficiales:\n",
        "    # Busca el nombre más parecido en la lista de Zillow\n",
        "    match = process.extractOne(barrio, nombres_zillow)\n",
        "\n",
        "    if match:\n",
        "        nombre_encontrado, score = match\n",
        "        # Si la similitud es alta (>80%), cogemos el precio\n",
        "        if score >= 80:\n",
        "            mapa_precios[barrio] = dict_precios[nombre_encontrado]\n",
        "        else:\n",
        "            mapa_precios[barrio] = None\n",
        "    else:\n",
        "        mapa_precios[barrio] = None\n",
        "\n",
        "# Sobreescribimos df_home_value con los nombres de neighborhood correcto\n",
        "df_home_value = pd.DataFrame(list(mapa_precios.items()), columns=['Neighborhood', 'Avg_price'])\n",
        "\n",
        "# Rellenamos los barrios que no se encontraron con el precio promedio del barrio\n",
        "promedio_global = df_home_value['Avg_price'].mean()\n",
        "df_home_value['Avg_price'] = df_home_value['Avg_price'].fillna(promedio_global)\n",
        "\n",
        "df_home_value.head()"
      ],
      "metadata": {
        "id": "tC6o2w8mfAeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataFrame final para representarlo en el frontend"
      ],
      "metadata": {
        "id": "bCGadWM4Qrx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Juntamos las columnas necesarias de los anteriores dataframes en uno final que contenga todos los features necesarios\n",
        "# para poder hacer la elección de barrio en base al input del usuario.\n",
        "df_final = gdf_barrios[['Neighborhood']].copy()\n",
        "\n",
        "# Añadimos la densidad de población\n",
        "df_final = df_final.merge(\n",
        "    df_demografia_barrio[['Neighborhood', 'Densidad_Poblacion']],\n",
        "    on = 'Neighborhood',\n",
        "    how = 'left'\n",
        ")\n",
        "\n",
        "# Añadimos los servicios y transportes\n",
        "df_final = df_final.merge(\n",
        "    servicios,\n",
        "    on = 'Neighborhood',\n",
        "    how = 'left'\n",
        ")\n",
        "\n",
        "# Añadimos los crimenes\n",
        "df_final = df_final.merge(\n",
        "    num_crimenes_barrio,\n",
        "    on = 'Neighborhood',\n",
        "    how = 'left'\n",
        ")\n",
        "\n",
        "# Añadimos el precio de la vivienda\n",
        "df_final = df_final.merge(\n",
        "    df_home_value,\n",
        "    on = 'Neighborhood',\n",
        "    how = 'left'\n",
        ")\n",
        "df_final\n"
      ],
      "metadata": {
        "id": "Uzb_t-UWQvsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalización y escalado de los datos"
      ],
      "metadata": {
        "id": "KD7wwIvmUXi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscamos todo lo que sea número (int, float) automáticamente\n",
        "columnas_numericas = df_final.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cols_sin_escalar = ['Neighborhood']\n",
        "cols_a_escalar = [col for col in columnas_numericas if col not in cols_sin_escalar]\n",
        "\n",
        "# Inicializamos el scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Normalizamos los datos\n",
        "df_final[cols_a_escalar] = scaler.fit_transform(df_final[cols_a_escalar])\n",
        "df_final['security'] = 1 - df_final['Crimenes_Barrio']\n",
        "\n",
        "# Printamos el dataframe\n",
        "df_final\n",
        "\n",
        "# Exportamos como csv el dataframe final\n",
        "df_final.to_csv('model_data.csv', index=True, sep=';')"
      ],
      "metadata": {
        "id": "jC-TCwy6UaGk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}